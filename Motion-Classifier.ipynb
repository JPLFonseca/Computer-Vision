{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c6e174-6723-4f87-b275-30322e03986e",
   "metadata": {},
   "source": [
    "## Instituto Superior de Engenharia de Lisboa \n",
    "## LEIM - 2024/2025\n",
    "### PIV - Processamento de Imagem e Visão\n",
    "\n",
    "# <br>\n",
    "\n",
    "#### <center> Trabalho Prático 2.A - Estimação e Classificação de Movimento </center>\n",
    "<b> <center> Grupo 14 </center> </b> \n",
    "# <br>\n",
    "\n",
    "\n",
    "\n",
    "Trabalho realizado por:\n",
    "\n",
    "* João Fonseca nº<b> 49707 </b>\n",
    "* Diogo Coito nº<b> 50029 </b>\n",
    "\n",
    " Docente: Pedro Mendes Jorge \n",
    "# <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4bf550-8667-40f1-82ec-c64fbcc7db65",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7a0f1-be68-47aa-97ed-c25dc61cc5fa",
   "metadata": {},
   "source": [
    "Neste segundo trabalho prático, foi-nos pedido para desenvolver um algoritmo de estimação e classificação de movimento. Para isso, dividimos o processo de elaboração deste em 3 partes:\n",
    "\n",
    "- Deteção da região da mão \n",
    "- Classificação dos movimentos\n",
    "- Fazer a representação gráfica\n",
    "\n",
    "Cada um destes passos vai ser abordado de forma mais detalhada no desenvolvimento do relatório, bem como o código produzido de maneira a atingir o objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48eb874-8c19-4b0d-82ee-26385e0363d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d429c9d-7870-4c92-88d2-117f2294c7b3",
   "metadata": {},
   "source": [
    "## Desenvolvimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fd963-b40d-49fb-b750-e8645960aa33",
   "metadata": {},
   "source": [
    "#### 1. Deteção e seguimento da região da mão\n",
    "\n",
    "Neste primeiro passo, procurámos isolar a mão do resto do conteúdo que a câmera capta, de maneira a obter os contornos desta. Para isso, decidimos que a melhor maneira seria através da deteção do tom de pele. Como o tom de pele pode variar de acordo com a intensidade da luz e a direção desta, começámos por converter a imagem recebida para HSV por este formato nos dar mais controlo sobre a luminosidade e saturação. Seguidamente, definimos valores mínimos e máximos de maneira a fazer a binarização da imagem e fazer a extração dos seus contornos. Após obtermos os contornos, é preciso definir aquelas que pertencem à mão. Para isso, definimos algumas condições que fazem com que contornos com área inferior a 5000 não sejam tidos em conta e que o contorno com a coordenada y mais baixa seja identificado como sendo a mão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3027e869-5092-4fdb-ad56-a9ede2eaebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detetaMao(img):\n",
    "\n",
    "    # conversão da image de RGB para HSV. Neste caso, o HSV é mais vantajoso relativamente ao RGB por permiter definir a saturação e o brilho\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # limites definidos para detetar o tom de pele\n",
    "    limiar_baixo = np.array([0, 40, 50])\n",
    "    limiar_cima = np.array([20, 150, 255])\n",
    "    \n",
    "    nova_img = cv2.inRange(img_hsv, limiar_baixo, limiar_cima) # binarização da imagem\n",
    "    \n",
    "    # operadores morfológicos de abertura e fecho\n",
    "    op = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    nova_img = cv2.morphologyEx(nova_img, cv2.MORPH_CLOSE, op)\n",
    "    nova_img = cv2.morphologyEx(nova_img, cv2.MORPH_OPEN, op)\n",
    "    \n",
    "    contornos, _ = cv2.findContours(nova_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contorno_malto = None\n",
    "    for contorno in contornos:\n",
    "        area = cv2.contourArea(contorno)\n",
    "        if area > 5000: \n",
    "            x, y, larg, alt = cv2.boundingRect(contorno)\n",
    "            if not contorno_malto or y < contorno_malto['y']:\n",
    "                contorno_malto = {'x': x, 'y': y, 'largura': larg, 'altura': alt, 'area': area}\n",
    "    \n",
    "    return contorno_malto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f684c3f-5536-4cb9-8d43-c796a1df22a6",
   "metadata": {},
   "source": [
    "#### 2. Classificação dos movimentos\n",
    "\n",
    "Tendo o contorno que define a mão identificado, precisámos de identificar os tipos de movimentos realizados por esta. Estes podiam ser ESQUERDA, DIREITA, CIMA, BAIXO, ZOOM IN e ZOOM OUT. Para isso fizémos uma análise das coordenas x e y, bem como da área dos contornos em imagens consecutivas para fazer essa classificação.\n",
    "\n",
    "A partir dos nossos testes, concluímos que a mão não está sempre estável do ponto de vista computacional e para ter uma identificação de movimentos fidedigna precisávamos de criar uma função que não tivesse em conta pequenas alterações nas coordenadas. Por isso, criámos uma função de suavização das coordenadas.\n",
    "\n",
    "A classificação de movimentos é feita da seguinte maneira: são verificadas as coordenadas e área da posição atual e da posição anterior, estando estas guardadas num array. É calculada a variação de coordenas e área entre as duas posições e com base nisso o movimento é classificado. As condições para a sua classificação são as seguintes:\n",
    "- Se a variação das coordenadas e da área for inferior aos limiares definidos, é classificado como não havendo movimento\n",
    "- Se a variação da área for superior ao limiar de área definido, é classificado como ZOOM IN\n",
    "- Se a variação da área for inferior ao valor negativo do limiar de área definido, é classificado como ZOOM OUT\n",
    "- Se a variação no eixo do x for superior à variação do eixo do y e a variação de x tiver um valor positivo, é classificado como DIREITA\n",
    "- Se a variação no eixo do x for superior à variação do eixo do y e a variação de x tiver um valor negativo, é classificado como ESQUERDA\n",
    "- Se a variação no eixo do y for superior à variação do eixo do x e a variação de y tiver um valor positivo, é classificado como BAIXO\n",
    "- Se a variação no eixo do y for superior à variação do eixo do x e a variação de y tiver um valor negativo, é classificado como CIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c8230d-09d0-4fe3-b212-eff30c8290a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para suavizar os movimentos\n",
    "def smoothValues(current_value, previous_value, smoothing_factor=0.8):\n",
    "    return smoothing_factor*previous_value+(1-smoothing_factor)*current_value\n",
    "\n",
    "# função de classificação dos movimentos\n",
    "def classifyMovement(posicoes, thresholds):\n",
    "    \n",
    "    if len(posicoes) < 2:\n",
    "        return \"Sem Movimento\"\n",
    "\n",
    "    # vai buscar os dois últimos movimentos registados\n",
    "    anterior = posicoes[-2]\n",
    "    atual = posicoes[-1]\n",
    "    \n",
    "    dx = atual['x'] - anterior['x']\n",
    "    dy = atual['y'] - anterior['y']\n",
    "    d_area = atual['area'] - anterior['area']\n",
    "\n",
    "    if abs(dx) < thresholds['dx'] and abs(dy) < thresholds['dy'] and abs(d_area) < thresholds['d_area']:# filtra pequenas variações \n",
    "        return \"Sem Movimento\"\n",
    "\n",
    "    # classificar com base nas mudanças de coordendas ou área\n",
    "    if d_area > thresholds['d_area']:  \n",
    "        return \"Zoom In\"\n",
    "        \n",
    "    elif d_area < -thresholds['d_area']: \n",
    "        return \"Zoom Out\"\n",
    "        \n",
    "    elif abs(dx) > abs(dy):  \n",
    "        return \"Direita\" if dx > 0 else \"Esquerda\"\n",
    "        \n",
    "    elif abs(dy) > abs(dx):\n",
    "        return \"Baixo\" if dy > 0 else \"Cima\"\n",
    "    \n",
    "    return \"Sem movimento\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detetaMao(img):\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    limiar_baixo = np.array([0, 40, 50])\n",
    "    limiar_cima = np.array([20, 150, 255])\n",
    "\n",
    "    nova_img = cv2.inRange(img_hsv, limiar_baixo, limiar_cima)\n",
    "\n",
    "    op = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    nova_img = cv2.morphologyEx(nova_img, cv2.MORPH_CLOSE, op)\n",
    "    nova_img = cv2.morphologyEx(nova_img, cv2.MORPH_OPEN, op)\n",
    "\n",
    "    contornos, _ = cv2.findContours(nova_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contorno_malto = None\n",
    "\n",
    "    for contorno in contornos:\n",
    "        area = cv2.contourArea(contorno)\n",
    "        if area > 5000:\n",
    "            x, y, larg, alt = cv2.boundingRect(contorno)\n",
    "            if not contorno_malto or y < contorno_malto['y']:\n",
    "                contorno_malto = {'x': x, 'y': y, 'largura': larg, 'altura': alt, 'area': area}\n",
    "\n",
    "    return contorno_malto\n",
    "\n",
    "def smoothValues(current_value, previous_value, smoothing_factor=0.8):\n",
    "    return smoothing_factor * previous_value + (1 - smoothing_factor) * current_value\n",
    "\n",
    "def classifyMovement(posicoes, thresholds):\n",
    "    if len(posicoes) < 2:\n",
    "        return \"Sem Movimento\"\n",
    "\n",
    "    anterior = posicoes[-2]\n",
    "    atual = posicoes[-1]\n",
    "\n",
    "    dx = atual['x'] - anterior['x']\n",
    "    dy = atual['y'] - anterior['y']\n",
    "    d_area = atual['area'] - anterior['area']\n",
    "\n",
    "    if abs(dx) < thresholds['dx'] and abs(dy) < thresholds['dy'] and abs(d_area) < thresholds['d_area']:\n",
    "        return \"Sem Movimento\"\n",
    "\n",
    "    if d_area > thresholds['d_area']:\n",
    "        return \"Zoom In\"\n",
    "    elif d_area < -thresholds['d_area']:\n",
    "        return \"Zoom Out\"\n",
    "    elif abs(dx) > abs(dy):\n",
    "        return \"Direita\" if dx > 0 else \"Esquerda\"\n",
    "    elif abs(dy) > abs(dx):\n",
    "        return \"Baixo\" if dy > 0 else \"Cima\"\n",
    "\n",
    "    return \"Sem Movimento\"\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "posicoes = []\n",
    "limiares = {'dx':20,'dy':20,'d_area':1500}  \n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()    \n",
    "    posicao_atual = detetaMao(frame)\n",
    "    if posicao_atual:\n",
    "        posicoes.append(posicao_atual)\n",
    "        if len(posicoes) > 10:\n",
    "            posicoes.pop(0)\n",
    "        movimento = classifyMovement(posicoes, limiares)\n",
    "        cv2.rectangle(frame, (posicao_atual['x'], posicao_atual['y']),\n",
    "                      (posicao_atual['x'] + posicao_atual['largura'], posicao_atual['y'] + posicao_atual['altura']),\n",
    "                      (0, 255, 0), 2)\n",
    "        cv2.putText(frame, movimento, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Deteta mao\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826d1e5-6f9a-448a-b90f-66a962d05b67",
   "metadata": {},
   "source": [
    "#### 3. Representação gráfica\n",
    "\n",
    "Neste último passo, era apenas preciso fazer o desenho gráfico do objeto que queriámos e corresponder o seu movimento às classificações feitas do movimento da mão. Para isso construímos um triângulo, definindo um tamanho e as coordenadas centrais. Este tamanho e coordenadas vão ser guardados em variáveis globais de maneira a que sejam ajustados de acordo com os movimentos.\n",
    "Quando um movimento é detetado e classificado, o triângulo ajusta a sua posição ou tamanho de acordo com este. Por exemplo, quando é detetado o movimento ESQUERDA, a coordenada x do centro do triângulo tem o seu valor decrementado em 20 unidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b45247a-61d2-4a19-b7b9-ae5a9590bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_center = [300, 300] \n",
    "triangle_size = 50  \n",
    "\n",
    "\n",
    "def draw_triangle(frame, center, size):\n",
    "    \n",
    "    vertices = np.array([ [center[0],center[1]-size],[center[0]-size,center[1]+size],[center[0]+size,center[1]+size]])\n",
    "    cv2.polylines(frame, [vertices], isClosed=True, color=(0, 255, 0), thickness=3) # desenha o triângulo\n",
    "\n",
    "    return frame\n",
    "\n",
    "# atualização da posição do triângulo\n",
    "def update_triangle(movement, center, size, move_step, zoom_step):\n",
    "    \n",
    "    if movement == \"Direita\":\n",
    "        center[0] += move_step\n",
    "    elif movement == \"Esquerda\":\n",
    "        center[0] -= move_step\n",
    "    elif movement == \"Cima\":\n",
    "        center[1] -= move_step\n",
    "    elif movement == \"Baixo\":\n",
    "        center[1] += move_step\n",
    "    elif movement == \"Zoom In\":\n",
    "        size += zoom_step\n",
    "    elif movement == \"Zoom Out\":\n",
    "        size = max(size-zoom_step, 10) # evita que o triângulo diminua em excesso\n",
    "\n",
    "    return center, size\n",
    "\n",
    "\n",
    "def teste3():\n",
    "    \n",
    "    global triangle_center, triangle_size\n",
    "    \n",
    "    window_name = \"Animação\"\n",
    "    frame = np.zeros((800,800,3))\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    posicoes = []\n",
    "    smoothed_position = {'x':0,'y':0,'area':0}  \n",
    "    # Limiares de movimento\n",
    "    limiares = {'dx':20,'dy':20,'d_area':1500}  \n",
    "    posicoes = [] \n",
    "    move_step = 20 \n",
    "    zoom_step = 50 \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        hand = detetaMao(img)\n",
    "        \n",
    "        if hand:\n",
    "            # Ajustar os valores de maneira a que as ações não mudem rapidamente\n",
    "            smoothed_position['x'] = smoothValues(hand['x'],smoothed_position['x'])\n",
    "            smoothed_position['y'] = smoothValues(hand['y'],smoothed_position['y'])\n",
    "            smoothed_position['area'] = smoothValues(hand['area'],smoothed_position['area'])\n",
    "            posicoes.append(smoothed_position.copy())\n",
    "            \n",
    "            if len(posicoes) > 30:\n",
    "                posicoes.pop(0)\n",
    "\n",
    "            movement = classifyMovement(posicoes, limiares)# classificação do movimento\n",
    "            triangle_center,triangle_size = update_triangle(movement,triangle_center,triangle_size,move_step,zoom_step) # atualização da \n",
    "                                                                                                                        # posição do triângulo \n",
    "        frame = np.zeros((800,800,3))\n",
    "        frame = draw_triangle(frame,triangle_center,triangle_size)\n",
    "        cv2.putText(frame,f\"Movement: {movement}\",(10, 50),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255, 255, 255),2)\n",
    "        cv2.imshow(window_name,frame)\n",
    "\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "teste3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbedf2ee-dcf7-47f9-bf4b-e2dee64350ff",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb2679e-7ee2-42c5-b44c-e33534a5cf88",
   "metadata": {},
   "source": [
    "Em jeito de conclusão, o trabalho alcançou o seu objetivo final de estimar e classifar movimentos, exemplificando o seu bom funcionamento através de uma aplicação gráfica interativa. A biblioteca OpenCV revelou-se extremamente útil nesta trabalho, tendo sido utilizada na maioria dos passos do trabalho. No entanto, o bom funcionamento deste não consegue ser sempre garantido, pois se as condições de luminosidade e o conteúdo captado pela câmera não se assemelhar às condições de teste, podem afetar o resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f2756-8433-4313-adaf-b0fbc5b1e89c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
